#!/usr/bin/env python
# vcfsynth 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import dxpy
import dx_utils
import glob

@dxpy.entry_point('main')
def main(**job_inputs):
    # run SURVIVOR on VCFs to generate a standardized merged input
    dx_utils.run_cmd(["SURVIVOR", "--help"])

    # generate merged "truth set" VCF
    output_ref_csv = "merged_reference.csv"

    truth_vcfs = [dx_utils.download_and_gunzip_file(vcf, skip_decompress=True) for vcf in job_inputs['vcf_truth_set']]
    truthset_vcf = "truth_set.TRUTH.vcf"
    if len(job_inputs['vcf_truth_set']) > 1:
        # merge the VCFs into a single truth set
        with open("truth_filelist.txt", "w") as f:
            for vcf in truth_vcfs:
                f.write(vcf+'\n')

        # run SURVIVOR on truth set
        dx_utils.run_cmd(["SURVIVOR", "merge", "truth_filelist.txt", "1000", "1", "1", "0", "0", "10", truthset_vcf])
    else:
        dx_utils.run_cmd(["mv", truth_vcfs[0], truthset_vcf])

    # run SURVIVOR on VCFs to generate a standardized merged input
    dx_utils.run_cmd(["SURVIVOR", "merge", "--help"])

    # download the individual caller VCFs
    training_vcfs = [dx_utils.download_and_gunzip_file(vcf, skip_decompress=True) for vcf in job_inputs['sv_caller_results']]

    caller_names = []
    for vcf in training_vcfs:
        name = vcf.replace('.vcf', '').replace('.svtyped', '')
        caller_names.append(name.split('.')[-1])

    # run SURVIVOR on all VCFs
    with open("survivor_merge.txt", "w") as f:
        for vcf in training_vcfs:
            f.write(vcf + '\n')

    trainingset_vcf = "trainingset.vcf"
    dx_utils.run_cmd(["SURVIVOR", "merge", "survivor_merge.txt", "1000", "1", "1", "0", "0", "10", trainingset_vcf])

    # run SURVIVOR to see if trainingset present in truthset
    labels_vcf = "trainingset.labels.vcf"
    with open("labels_merge.txt", "w") as f:
        f.write(trainingset_vcf + "\n")
        f.write(truthset_vcf + "\n")

    dx_utils.run_cmd(["SURVIVOR", "merge", "labels_merge.txt", "1000", "1", "1", "0", "0", "10", labels_vcf])

    # compress, sort and index the labels vcf file
    dx_utils.run_cmd(['vcf-sort', labels_vcf], output_file=labels_vcf.replace('.vcf', '.sorted.vcf'))
    labels_vcf=labels_vcf.replace('.vcf', '.sorted.vcf')

    dx_utils.run_cmd(['bgzip', labels_vcf])
    labels_vcf += '.gz'

    dx_utils.run_cmd(['tabix', labels_vcf])

    # generate dataframe from merged VCF
    output_csv = "trainingset.csv"
    cmd = ['python', 'dataloader.py', '--vcf', trainingset_vcf, '--output', output_csv, '--ref', labels_vcf]
    for caller in caller_names:
        cmd += ['-s', caller]
    dx_utils.run_cmd(cmd)

    # now train the model
    dx_utils.run_cmd(['python', 'train_rf.py'])

    training_log = "model_validation.txt"
    tree_pngs = glob.glob("Tree_*.png")

    output = {
        "trainingdata_csv": dxpy.dxlink(dxpy.upload_local_file(output_csv)),
        "contained_model": dxpy.dxlink(dxpy.upload_local_file("model.pkl")),
        "model_evaluation": [dxpy.dxlink(dxpy.upload_local_file(training_log))],
        "model_visualization": [dxpy.dxlink(dxpy.upload_local_file(f)) for f in tree_pngs]
              }
    return output

dxpy.run()
